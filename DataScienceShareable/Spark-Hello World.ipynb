{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Spark session \n",
    "to ensure it is running an see how many nodes are running in the cluser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-7U9DJKGB:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fc94f617f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting up the spark context using command 'pyspark --master local[#ofNodes]'\n",
    "spark  # also achieved by through the \"sc\" object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the \"Hello World\" code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql('''SELECT 'spark' as hello ''') \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic file loading and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile = spark.read.text(\"C:\\\\Spark\\\\README.md\")\n",
    "# textFile\n",
    "textFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(value='# Apache Spark')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textFile.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineswithSpark = textFile.filter(textFile.value.contains(\"Spark\"))\n",
    "lineswithSpark.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory code based on Pluralsight course examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations in the SQL Context wrapper\n",
    "Some manipulations that handled differently between RDD's and DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "dfrange = sqlContext.range(5)\n",
    "dfrange.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n",
      "| ID|   Name|Score|\n",
      "+---+-------+-----+\n",
      "|  1|  Alice|   50|\n",
      "|  2|    Bob|   80|\n",
      "|  3|Charlee|   75|\n",
      "+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simple_data2 = [(1, \"Alice\", 50),\n",
    "                (2, \"Bob\", 80),\n",
    "                (3, \"Charlee\", 75)]\n",
    "sqlContext.createDataFrame(simple_data2, [\"ID\", \"Name\", \"Score\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='Alice', score=50),\n",
       " Row(id=2, name='Bob', score=80),\n",
       " Row(id=3, name='Charlee', score=75)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import Row\n",
    "data1 = sc.parallelize([\n",
    "    Row(1, \"Alice\", 50),\n",
    "    Row(2, \"Bob\", 80),\n",
    "    Row(3, \"Charlee\", 75)])\n",
    "col_names = Row('id', 'name', 'score')\n",
    "students = data1.map(lambda r: col_names(*r))\n",
    "students.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n",
      "| id|   name|score|\n",
      "+---+-------+-----+\n",
      "|  1|  Alice|   50|\n",
      "|  2|    Bob|   80|\n",
      "|  3|Charlee|   75|\n",
      "+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df = sqlContext.createDataFrame(students)\n",
    "students_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df.collect()[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   name|score|\n",
      "+-------+-----+\n",
      "|  Alice|   50|\n",
      "|    Bob|   80|\n",
      "|Charlee|   75|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select('name', 'score').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|score|final score|\n",
      "+-----+-----------+\n",
      "|   50|       55.5|\n",
      "|   80|       85.5|\n",
      "|   75|       80.5|\n",
      "+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select('score').withColumn('final score', students_df.score + 5.5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+\n",
      "| id|   name|old score|\n",
      "+---+-------+---------+\n",
      "|  1|  Alice|       50|\n",
      "|  2|    Bob|       80|\n",
      "|  3|Charlee|       75|\n",
      "+---+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.withColumnRenamed(\"score\", \"old score\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|old score|\n",
      "+---------+\n",
      "|       50|\n",
      "|       80|\n",
      "|       75|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.select(students_df.score.alias('old score')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlee</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     name  score\n",
       "0   1    Alice     50\n",
       "1   2      Bob     80\n",
       "2   3  Charlee     75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "students_pandas = students_df.toPandas()\n",
    "students_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n",
      "| id|   name|score|\n",
      "+---+-------+-----+\n",
      "|  1|  Alice|   50|\n",
      "|  2|    Bob|   80|\n",
      "|  3|Charlee|   75|\n",
      "+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = sqlContext.createDataFrame(students_pandas).show()\n",
    "df_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+\n",
      "| id|   name|score|\n",
      "+---+-------+-----+\n",
      "|  1|  Alice|   50|\n",
      "|  2|    Bob|   80|\n",
      "|  3|Charlee|   75|\n",
      "+---+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "students_df.show()  # the original DataFrame is never changed. All transformations create new DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|lsoa_code|   borough|      major_category|      minor_category|value|year|month|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "|E01001116|   Croydon|            Burglary|Burglary in Other...|    0|2016|   11|\n",
      "|E01001646| Greenwich|Violence Against ...|      Other violence|    0|2016|   11|\n",
      "|E01000677|   Bromley|Violence Against ...|      Other violence|    0|2015|    5|\n",
      "|E01003774| Redbridge|            Burglary|Burglary in Other...|    0|2016|    3|\n",
      "|E01004563|Wandsworth|             Robbery|   Personal Property|    0|2008|    6|\n",
      "|E01001320|    Ealing|  Theft and Handling|         Other Theft|    0|2012|    5|\n",
      "|E01001342|    Ealing|Violence Against ...|    Offensive Weapon|    0|2010|    7|\n",
      "|E01002633|  Hounslow|             Robbery|   Personal Property|    0|2013|    4|\n",
      "|E01003496|    Newham|     Criminal Damage|Criminal Damage T...|    0|2013|    9|\n",
      "|E01004177|    Sutton|  Theft and Handling|Theft/Taking of P...|    1|2016|    8|\n",
      "+---------+----------+--------------------+--------------------+-----+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filePath = \"..\\\\Courses&InputData\\\\spark-2-getting-started\\\\02\\\\demos\\\\datasets\\\\london_crime_by_lsoa.csv\"\n",
    "data = spark.read.format('csv').option('header', 'true').load(filePath)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13490604"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.collect()  # prints out all the data. don't do this with large datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
